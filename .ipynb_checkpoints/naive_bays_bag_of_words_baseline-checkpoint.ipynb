{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.read_csv('mbti_1.csv')\n",
    "\n",
    "# replace URLs\n",
    "\n",
    "# replace MBTI\n",
    "# https://stackoverflow.com/questions/16720541/python-string-replace-regular-expression/16720705\n",
    "mbti_pat = r\"ISFJ|ESFP|ISFP|ISTP|ENFP|ENFJ|INFJ|ESTP|ESFJ|ESTJ|ENTP|INFP|INTP|INTJ|ISTJ|ENTJ\"\n",
    "mbti_regex = re.compile(mbti_pat, re.IGNORECASE)\n",
    "MBTI_REP = '$MBTI$'\n",
    "\n",
    "# replace hashtags\n",
    "hashtag_pat = r\"(\\#[a-zA-Z0-9]+\\b)\"\n",
    "hashtag_regex = re.compile(hashtag_pat)\n",
    "HASHTAG_REP = '$HASHTAG$'\n",
    "\n",
    "# Replace links with $link$\n",
    "# https://stackoverflow.com/questions/3809401/what-is-a-good-regular-expression-to-match-a-url\n",
    "link_pat = r\"(http(s)?:\\/\\/.)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\"\n",
    "LINK_REP = '$LINK$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['posts'] = df['posts'].apply(lambda x: re.sub(mbti_pat, MBTI_REP, x))\n",
    "df['posts'] = df['posts'].apply(lambda x: re.sub(hashtag_pat, HASHTAG_REP, x))\n",
    "df['posts'] = df['posts'].apply(lambda x: re.sub(link_pat, LINK_REP, x))\n",
    "\n",
    "\n",
    "df['posts'] = df['posts'].apply(lambda x: x.replace('|||', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IE'] = df['type'].apply(lambda x: 'I' if x[0] == 'I' else 'E')\n",
    "df['NS'] = df['type'].apply(lambda x: 'N' if x[1] == 'N' else 'S')\n",
    "df['FT'] = df['type'].apply(lambda x: 'F' if x[2] == 'F' else 'T')\n",
    "df['PJ'] = df['type'].apply(lambda x: 'P' if x[3] == 'P' else 'J')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type', 'posts', 'IE', 'NS', 'FT', 'PJ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ie = df[['type', 'posts', 'IE']]\n",
    "df_ns = df[['type', 'posts', 'NS']]\n",
    "df_ft = df[['type', 'posts', 'FT']]\n",
    "df_pj = df[['type', 'posts', 'PJ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Double data values for underrepresented traits\n",
    "# df_ie = df_ie.append(df_ie[df_ie['IE'] == 'E'])\n",
    "# df_ns = df_ns.append(df_ns[df_ns['NS'] == 'S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pct = 0.6\n",
    "\n",
    "# indicates the location to split the data along\n",
    "# since dev/test are the same size\n",
    "test_split_position = 1.0 - (1.0 - train_pct) / 2\n",
    "test_split_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ie, dev_ie, test_ie = np.split(df_ie.sample(frac=1, random_state = 224), [int(train_pct*len(df_ie)), int(test_split_position*len(df_ie))])\n",
    "train_ns, dev_ns, test_ns = np.split(df_ns.sample(frac=1, random_state = 224), [int(train_pct*len(df_ns)), int(test_split_position*len(df_ns))])\n",
    "train_ft, dev_ft, test_ft = np.split(df_ft.sample(frac=1, random_state = 224), [int(train_pct*len(df_ft)), int(test_split_position*len(df_ft))])\n",
    "train_pj, dev_pj, test_pj = np.split(df_pj.sample(frac=1, random_state = 224), [int(train_pct*len(df_pj)), int(test_split_position*len(df_pj))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>IE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'I didn't even realize how impassive I looked ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6554</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm actually going into the Counseling Psycho...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'I can't articulate this problem very well. I ...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>'I'm thankful for my boyfriend, he's my rock o...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'Great! I sent you a challenge. :)I'm a marrie...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts IE\n",
       "3041  INTJ  'I didn't even realize how impassive I looked ...  I\n",
       "6554  ENTP  'I'm actually going into the Counseling Psycho...  E\n",
       "2139  ENFP  'I can't articulate this problem very well. I ...  E\n",
       "2114  ESTP  'I'm thankful for my boyfriend, he's my rock o...  E\n",
       "1675  INFP  'Great! I sent you a challenge. :)I'm a marrie...  I"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_ie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# baseline for IE\n",
    "train_counts_ie = count_vect.fit_transform(list(train_ie['posts']))\n",
    "train_counts_ie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsize_factor_ie = sum(train_ie['IE'] == 'E')/len(train_ie['IE'])\n",
    "train_weights_ie = [1 if ie == 'E' else downsize_factor_ie for ie in train_ie['IE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6463700234192038"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IE dev set\n",
    "text_clf.fit(train_ie['posts'], train_ie['IE'], **{'clf__sample_weight': train_weights_ie})  \n",
    "predicted_ie = text_clf.predict(dev_ie['posts'])\n",
    "np.mean(predicted_ie == dev_ie['IE'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score IE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.62972045, 0.66158673])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"f1 score IE\")\n",
    "\n",
    "f1_score(dev_ie['IE'], predicted_ie, labels=['I', 'E'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsize_factor_ns = sum(train_ns['NS'] == 'S')/len(train_ns['NS'])\n",
    "train_weights_ns = [1 if ns == 'S' else downsize_factor_ns for ns in train_ns['NS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7011144883485309"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])\n",
    "text_clf.fit(train_ns['posts'], train_ns['NS'], **{'clf__sample_weight': train_weights_ns})  \n",
    "predicted_ns = text_clf.predict(dev_ns['posts'])\n",
    "np.mean(predicted_ns == dev_ns['NS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score NS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.76305221, 0.59533608])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"f1 score NS\")\n",
    "f1_score(dev_ns['NS'], predicted_ns, labels=['N', 'S'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsize_factor_ft = sum(train_ft['FT'] == 'T')/len(train_ft['FT'])\n",
    "train_weights_ft = [1 if ft == 'T' else downsize_factor_ft for ft in train_ft['FT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7175792507204611"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])\n",
    "text_clf.fit(train_ft['posts'], train_ft['FT'], **{'clf__sample_weight': train_weights_ft})  \n",
    "predicted_ft = text_clf.predict(dev_ft['posts'])\n",
    "np.mean(predicted_ft == dev_ft['FT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score FT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.67506631, 0.75025484])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"f1 score FT\")\n",
    "f1_score(dev_ft['FT'], predicted_ft, labels=['F', 'T'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsize_factor_pj = sum(train_pj['PJ'] == 'J')/len(train_pj['PJ'])\n",
    "train_weights_pj = [1 if pj == 'J' else downsize_factor_pj for pj in train_pj['PJ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4795389048991354"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])\n",
    "text_clf.fit(train_pj['posts'], train_pj['PJ'], **{'clf__sample_weight': train_weights_pj})  \n",
    "predicted_pj = text_clf.predict(dev_pj['posts'])\n",
    "np.mean(predicted_pj == dev_pj['PJ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score PJ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.312262, 0.581363])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"f1 score PJ\")\n",
    "f1_score(dev_pj['PJ'], predicted_pj, labels=['P', 'J'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1735,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_pj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[['E' 'I']\n",
      " ['1446' '689']]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(predicted_ie, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw counts\n",
      "I    6676\n",
      "E    3998\n",
      "Name: IE, dtype: int64\n",
      "N    7478\n",
      "S    2394\n",
      "Name: NS, dtype: int64\n",
      "F    4694\n",
      "T    3981\n",
      "Name: FT, dtype: int64\n",
      "P    5241\n",
      "J    3434\n",
      "Name: PJ, dtype: int64\n",
      "\n",
      "\n",
      "Prediction distribution\n",
      "Counter({'E': 1446, 'I': 689})\n",
      "Counter({'N': 997, 'S': 977})\n",
      "Counter({'T': 1158, 'F': 577})\n",
      "Counter({'J': 1481, 'P': 254})\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw counts\")\n",
    "print(df_ie['IE'].value_counts())\n",
    "print(df_ns['NS'].value_counts())\n",
    "print(df_ft['FT'].value_counts())\n",
    "print(df_pj['PJ'].value_counts())\n",
    "\n",
    "\n",
    "import collections\n",
    "print(\"\\n\\nPrediction distribution\")\n",
    "print(collections.Counter(predicted_ie))\n",
    "print(collections.Counter(predicted_ns))\n",
    "print(collections.Counter(predicted_ft))\n",
    "print(collections.Counter(predicted_pj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
