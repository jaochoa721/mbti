{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found here: https://gist.github.com/jlln/338b4b0b55bd6984f883\n",
    "def splitDataFrameList(df,target_column,separator):\n",
    "    ''' df = dataframe to split,\n",
    "    target_column = the column containing the values to split\n",
    "    separator = the symbol used to perform the split\n",
    "    returns: a dataframe with each entry for the target column separated, with each element moved into a new row. \n",
    "    The values in the other columns are duplicated across the newly divided rows.\n",
    "    '''\n",
    "    def splitListToRows(row,row_accumulator,target_column,separator):\n",
    "        split_row = row[target_column].split(separator)\n",
    "        for s in split_row:\n",
    "            new_row = row.to_dict()\n",
    "            new_row[target_column] = s\n",
    "            row_accumulator.append(new_row)\n",
    "    new_rows = []\n",
    "    df.apply(splitListToRows,axis=1,args = (new_rows,target_column,separator))\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('mbti_1.csv')\n",
    "\n",
    "df = splitDataFrameList(df_orig, 'posts', '|||')\n",
    "\n",
    "\n",
    "# replace URLs\n",
    "\n",
    "# replace MBTI\n",
    "# https://stackoverflow.com/questions/16720541/python-string-replace-regular-expression/16720705\n",
    "mbti_pat = r\"ISFJ|ESFP|ISFP|ISTP|ENFP|ENFJ|INFJ|ESTP|ESFJ|ESTJ|ENTP|INFP|INTP|INTJ|ISTJ|ENTJ\"\n",
    "mbti_regex = re.compile(mbti_pat, re.IGNORECASE)\n",
    "MBTI_REP = '$MBTI$'\n",
    "\n",
    "# replace hashtags\n",
    "hashtag_pat = r\"(\\#[a-zA-Z0-9]+\\b)\"\n",
    "hashtag_regex = re.compile(hashtag_pat)\n",
    "HASHTAG_REP = '$HASHTAG$'\n",
    "\n",
    "# Replace links with $link$\n",
    "# https://stackoverflow.com/questions/3809401/what-is-a-good-regular-expression-to-match-a-url\n",
    "link_pat = r\"(http(s)?:\\/\\/.)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\"\n",
    "LINK_REP = '$LINK$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['posts'] = df['posts'].apply(lambda x: re.sub(mbti_pat, MBTI_REP, x))\n",
    "df['posts'] = df['posts'].apply(lambda x: re.sub(hashtag_pat, HASHTAG_REP, x))\n",
    "df['posts'] = df['posts'].apply(lambda x: re.sub(link_pat, LINK_REP, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IE'] = df['type'].apply(lambda x: 'I' if x[0] == 'I' else 'E')\n",
    "df['NS'] = df['type'].apply(lambda x: 'N' if x[1] == 'N' else 'S')\n",
    "df['FT'] = df['type'].apply(lambda x: 'F' if x[2] == 'F' else 'T')\n",
    "df['PJ'] = df['type'].apply(lambda x: 'P' if x[3] == 'P' else 'J')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['posts', 'type', 'IE', 'NS', 'FT', 'PJ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ie = df[['type', 'posts', 'IE']]\n",
    "df_ns = df[['type', 'posts', 'NS']]\n",
    "df_ft = df[['type', 'posts', 'FT']]\n",
    "df_pj = df[['type', 'posts', 'PJ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Double data values for underrepresented traits\n",
    "# df_ie = df_ie.append(df_ie[df_ie['IE'] == 'E'])\n",
    "# df_ns = df_ns.append(df_ns[df_ns['NS'] == 'S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pct = 0.6\n",
    "\n",
    "# indicates the location to split the data along\n",
    "# since dev/test are the same size\n",
    "test_split_position = 1.0 - (1.0 - train_pct) / 2\n",
    "test_split_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ie, dev_ie, test_ie = np.split(df_ie.sample(frac=1, random_state = 224), [int(train_pct*len(df_ie)), int(test_split_position*len(df_ie))])\n",
    "train_ns, dev_ns, test_ns = np.split(df_ns.sample(frac=1, random_state = 224), [int(train_pct*len(df_ns)), int(test_split_position*len(df_ns))])\n",
    "train_ft, dev_ft, test_ft = np.split(df_ft.sample(frac=1, random_state = 224), [int(train_pct*len(df_ft)), int(test_split_position*len(df_ft))])\n",
    "train_pj, dev_pj, test_pj = np.split(df_pj.sample(frac=1, random_state = 224), [int(train_pct*len(df_pj)), int(test_split_position*len(df_pj))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>IE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28170</th>\n",
       "      <td>INTP</td>\n",
       "      <td>Turnitin is now going to crawl this website an...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379609</th>\n",
       "      <td>INTP</td>\n",
       "      <td>... I don't get it. It's supposed to be shocki...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94405</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>Thanks guys, I'll just keep on going and see w...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155565</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>I wouldn't dare, dude. I would feel bad to hur...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419648</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>I think you discover your values by witnessing...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                              posts IE\n",
       "28170   INTP  Turnitin is now going to crawl this website an...  I\n",
       "379609  INTP  ... I don't get it. It's supposed to be shocki...  I\n",
       "94405   ENFP  Thanks guys, I'll just keep on going and see w...  E\n",
       "155565  ENTP  I wouldn't dare, dude. I would feel bad to hur...  E\n",
       "419648  ISFP  I think you discover your values by witnessing...  I"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_ie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# baseline for IE\n",
    "train_counts_ie = count_vect.fit_transform(list(train_ie['posts']))\n",
    "train_counts_ie.shape\n",
    "\n",
    "train_weights_ie = [1.0/2]*len(train_ie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsize_factor_ie = sum(train_ie['IE'] == 'E')/len(train_ie['IE'])\n",
    "train_weights_ie = [1 if ie == 'E' else downsize_factor_ie for ie in train_ie['IE']]\n",
    "# train_weights_ie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5034154777345439"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IE dev set\n",
    "text_clf.fit(train_ie['posts'], train_ie['IE'], **{'clf__sample_weight': train_weights_ie})  \n",
    "predicted_ie = text_clf.predict(dev_ie['posts'])\n",
    "np.mean(predicted_ie == dev_ie['IE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score IE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.42479885, 0.563126  ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"f1 score IE\")\n",
    "\n",
    "f1_score(dev_ie['IE'], predicted_ie, labels=['I', 'E'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsize_factor_ns = sum(train_ns['NS'] == 'S')/len(train_ns['NS'])\n",
    "train_weights_ns = [1 if ns == 'S' else downsize_factor_ns for ns in train_ns['NS']]\n",
    "# train_weights_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49041320939131156"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])\n",
    "text_clf.fit(train_ns['posts'], train_ns['NS'], **{'clf__sample_weight': train_weights_ns})  \n",
    "predicted_ns = text_clf.predict(dev_ns['posts'])\n",
    "np.mean(predicted_ns == dev_ns['NS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score NS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5372362 , 0.43304837])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"f1 score NS\")\n",
    "f1_score(dev_ns['NS'], predicted_ns, labels=['N', 'S'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsize_factor_ft = sum(train_ft['FT'] == 'T')/len(train_ft['FT'])\n",
    "train_weights_ft = [1 if ft == 'T' else downsize_factor_ft for ft in train_ft['FT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5566697016637302"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])\n",
    "text_clf.fit(train_ft['posts'], train_ft['FT'], **{'clf__sample_weight': train_weights_ft})  \n",
    "predicted_ft = text_clf.predict(dev_ft['posts'])\n",
    "np.mean(predicted_ft == dev_ft['FT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score FT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.43933004, 0.63339461])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"f1 score FT\")\n",
    "f1_score(dev_ft['FT'], predicted_ft, labels=['F', 'T'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsize_factor_pj = sum(train_pj['PJ'] == 'J')/len(train_pj['PJ'])\n",
    "train_weights_pj = [1 if pj == 'J' else downsize_factor_pj for pj in train_pj['PJ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4559826886920739"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])\n",
    "text_clf.fit(train_pj['posts'], train_pj['PJ'], **{'clf__sample_weight': train_weights_pj})  \n",
    "predicted_pj = text_clf.predict(dev_pj['posts'])\n",
    "np.mean(predicted_pj == dev_pj['PJ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score PJ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.29733486, 0.55618687])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"f1 score PJ\")\n",
    "f1_score(dev_pj['PJ'], predicted_pj, labels=['P', 'J'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84569,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_pj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[['E' 'I']\n",
      " ['79367' '24718']]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(predicted_ie, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw counts\n",
      "I    325263\n",
      "E    195164\n",
      "Name: IE, dtype: int64\n",
      "N    364822\n",
      "S    116046\n",
      "Name: NS, dtype: int64\n",
      "F    229312\n",
      "T    193533\n",
      "Name: FT, dtype: int64\n",
      "P    255735\n",
      "J    167110\n",
      "Name: PJ, dtype: int64\n",
      "\n",
      "\n",
      "Prediction distribution\n",
      "Counter({'E': 79367, 'I': 24718})\n",
      "Counter({'S': 63369, 'N': 32805})\n",
      "Counter({'T': 63513, 'F': 21056})\n",
      "Counter({'J': 70277, 'P': 14292})\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw counts\")\n",
    "print(df_ie['IE'].value_counts())\n",
    "print(df_ns['NS'].value_counts())\n",
    "print(df_ft['FT'].value_counts())\n",
    "print(df_pj['PJ'].value_counts())\n",
    "\n",
    "\n",
    "import collections\n",
    "print(\"\\n\\nPrediction distribution\")\n",
    "print(collections.Counter(predicted_ie))\n",
    "print(collections.Counter(predicted_ns))\n",
    "print(collections.Counter(predicted_ft))\n",
    "print(collections.Counter(predicted_pj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
